Survey design check list

[TOC]

- [Survey interface【形式】](#survey-interface----)
  * [It needs to look good](#it-needs-to-look-good)
  * [First page](#first-page)
  * [Thank you & contact information](#thank-you---contact-information)
  * [Interviewer instructions](#interviewer-instructions)
  * [Numbering questions](#numbering-questions)
  * [Fitting questions on pages/screen](#fitting-questions-on-pages-screen)
  * [Ordering questions](#ordering-questions)
  * [Types of questions](#types-of-questions)
- [Questions and response options【内容】](#questions-and-response-options----)
  * [Ensure consistent response](#ensure-consistent-response)
  * [4 reasons respondents fail to answer factual questions and how to do](#4-reasons-respondents-fail-to-answer-factual-questions-and-how-to-do)
  * [Stylish responding and how to do](#stylish-responding-and-how-to-do)
  * [Subjective questions (increase validity)](#subjective-questions--increase-validity-)
  * [Pitfalls/check list](#pitfalls-check-list)
  * [Redflag words in question wording](#redflag-words-in-question-wording)
- [Web survey design settings 【设置】](#web-survey-design-settings-----)
  * [Avoid breakoffs](#avoid-breakoffs)
  * [Distribute web survey](#distribute-web-survey)
  * [Basic design](#basic-design)
  * [Question setting](#question-setting)
  * [Response format & scales](#response-format---scales)
  * [Response heuristics](#response-heuristics)



# Survey interface【形式】

## It needs to look good

- should be well-organized and professional
- should convey seriousness

## First page

- Put your university at the beginning
- should contain: name, where are you from, the purpose of the study, conditions (voluntary, anonymous, etc.)
- *To begin, just scroll down and click the "next" button*

## Thank you & contact information

- put at the beginning and the end of the survey
- make them serious
- you don't want the respondents to go back
- all contact information should look badass; don't look stupid and silly

 ## Interviewer instructions

- in different forms (so that instructions can be easily distinguished from other parts of the survey)
- put them to where it's going to be used
  - instructions about how to read the question should be put before the question
  - instructions about how much responses should be put before the question
  - Instructions about how to code should be put after the question

## Numbering questions

- always number questions
- number subparts with subscripts

> Reasons:
>
> - ability to get complaints/concerns about questions
> - satisficing: the respondents would feel like they are making progress

## Fitting questions on pages/screen

- don't break questions outside a page
- don't put a small question after a long question (otherwise the respondents will skip it by accident)
- unclusterred (otherwise it will look intimidating)

## Ordering questions

> Goals:
>
> - motivate the respondents to keep going (you don't want them to stop)
> - minimize question-order effects (the effect of one question on another one)

- the first question **should not be demographic questions**
  - the first question should be interesting
  - should concern you and should be related to the research
  - should not be income questions (most sensitive, respondents will quit or skip it)

> Reasons:
>
> - demographic questions have two purposes: make sure the eligibility (screening/attrition), and seeing what the respondents are like
> - if they feel like they are being screened, they lie
> - reduce anger
> - demographic information form

- leave some question before demographic questions
  - these questions should interest them
  - should be questions that everybody can answer
  - should be done in a non-threatenning way
  - should not be income questions (most sensitive, respondents will quit or skip it)

## Types of questions

- Open-ended questions

> - advantages: provide the riches detail; closely proximate what people actually think; great for pretest; provide answers theoretically impossible to provide; allow for unanticipated answers. 
>
> - disadvantages: put higher burden on respondents (tend to skip them); time consuming; contain irrelevant words; hard to answer on smart phones or on telephone; contain errors; difficult to code and interpret.

- close-ended questions (99% of times they are the best options)

> - advantages: more practical; alreadly coded; more reliable for respondents and researchers (they don't love to interpret it)
> - disadvantages: accuracy concerns; may leave out important categories; lose detail

- close-ended question with an open-ended stem (other option)

> - question: what do you think... / which of the following... (always highest in the list)
> - should be able to guess responses
> - 43% vs 8% in close-ended question specifying other category
> - 12% uninterpretable in open-ended questions
> - 0.8%/0% vs 41.2% missing in open-ended questions

- matrix questions with Likert statements (a series of questions sharing the same response scale, like level of agreement/acceptability/support/frequencies)
  - first couple of items should be in opposite direction
  - shadowing to differentiate the rows

> - advantages: use space more efficiently; easier for respondents to do; set the items being comparable

- contingency questions (based on anwers to some screening questions)

> - advantages: respondents won't answer irrelevant questions
> - disadvantages: hard to do (huge errors) unless using computers 

---



# Questions and response options【内容】

## Ensure consistent response

the most important and cheapest way to improve data is to increase reliability

1. make sure each respondent is asked the same question
   
- interviews should be entirely scripted (otherwise different things will be said to different people, and selected explanations & process will only be given to a certain people)
  
2. wording should be complete (otherwise different people will interpret the question differently)

3. wording should be simple, straightforward, and as short as possible (otherwise comprehension breaks down)

4. consistent meaning: words need to mean the same thing for everybody

   - avoid terms that are not universally understood
   - if terms are vague or ambiguous, define them differently
   - if terms are not vague but have inconsistent meaning for different people, avoid them

5. for open-ended questions, clarify acceptable type of answers (words or numbers)

   > eg. smaller box for MM, larger box for YYYY
   >
   > <textarea cols="2" rows="1">  </textarea>  MM <textarea cols="4" rows="1">  </textarea> YYYY 

6. avoid double-barrel questions (they reduce reliability)
7. avoid jargon & complex words/phrases (otherwise respondents would say don't know or the results will be less reliable)

## 4 reasons respondents fail to answer factual questions and how to do

1. respondents don't understand the question
   - make it easier

2. respondents don't know the answer
3. respondents cannot recall
   - Make it salient; recent; add cues
   - the reference period should be tailored to subjects
4. they don't want to tell you （social desirability bias)
   - use self-administered survey
   - tell the respondents the survey is anonymous and confidential



## Stylish responding and how to do

respond in similar consistent way, regardless of the context

|                                                              | Bias           |
| ------------------------------------------------------------ | -------------- |
| Acquiescence response style [XXXOOO]<br />tendency to affirmatively choose, regardless of the context; 10% | positive bias  |
| Disacquiescence response style [OOOXXX]<br />disagree consistently | positive bias  |
| midpoint response style [XXXOXXX]                            | positive error |
| extreme response style<br />go for the most extreme response | depends        |
| mild response style<br />always give middle response         | Depends        |

- use balanced scale to push to the middle

- midpoint is not as common

  - representative corresponsive index

  - groups of uncorrelated items

    > eg. I like Apples more than oranges 



## Subjective questions (increase validity)

1. face validity

2. content validity

   - use more than 1 question, and combine them to create a scale

   - make sure all dimensions of a concept are covered and all subcategories are covered

     > eg. fear of crime scale consists of 4 -5 questions covering violent/nonviolent, severe/nonsevere crimes

## Pitfalls/check list

- [ ] 1. not exhaustive?

  - include other option

- [ ] 2. not mutually exclusive?

- [ ] 3. question too long?

  - trim the question by 10%; keep only necessary words to faster the survey

- [ ] 4. question unbalanced? leading or suggesting an answer?

  - don't forget to mention the other side

- [ ] 5. prestige bias (someone people have positive or negative opinion about)?

  - don't unnecessarily include someone who the repondents will support or oppose

- [ ] 6. universal?

- [ ] 7. double-barreled?

- [ ] 8. poorly ordered?

  > Question order effect:
  >
  > - people want to be consistent
  > - priming: bring things up that you might not think about
  > - interpretation

  - global questions should come first, specific questions should come after them

  - randomize question order to balance it out 

    > eg. NLSY97 - 389
    >
    > eg. perceived arrest question comes before, this arrest question comes after (link arrest perception to actual arrest experience)

- [ ] 9. negative and double negative questions?

  - don't use "not" in questions
  - don't know should not have been there

- [ ] 10. using modifying adjectives 

  > eg. replace "occasionally" with "seldom," "occasionally" is vague

- [ ] 11. when to add don't know option

  - think about how likely people will not know

  > eg. people tend to undecided for voting: better to add don't know option
  >
  > eg. death penalty question: better not to add

- [ ] 12. when asking about numbers

  - should use standardized scale (more comparable)

  - should use benchmark (Ansolabehere, Meredith, & Snowberg, 2013)

    > eg. give historical range

- [ ] 13. anchoring vignette (compare to vignette, not used a lot in crim)

  > eg. below Moses, above Moses, or equal to Moses

  - ensure comparability of responses
  - compare to 2 persons 
    - ordering of the vignette
    - don't use direct comparison, since respondents tend to satisfice

- [ ] 14. focal answers in numerical questions

  - select more than you would expect that people tend to be drawn to

    > eg. choose among 0, 50, 100 (multiples of 5), normally modal is 50 (representing rounding or don't know)

- [ ] 15. violating conversational conventions (how people usually talk)?

  - convention: affirmative first; if against comes before for, it reduces response quality
  - number of irrelative thoughts distracts the respondents

- [ ] 16. number of response categories: 4 to 5 

  - 5 vs 7: overall quality 0.53 vs 0.39
  - unipolar vs bipolar: more categories, less reliable

- [ ] 17. information in question stem should reduce social desirability bias

  - quality best when use straightforward questions

    >  eg. some people, other people

- [ ] 18. information in response categories should look like population distribution

  - people assume the options are evenly split
  - people assume the middle one is average

- [ ] 19. stems and response options should match (otherwise response time will increase)



## Redflag words in question wording

- [ ] and (maybe double-barreled)
- [ ] not (respondents may overlook not; negative questions)
- [ ] or (false dilemma)
- [ ] if (confusing)

---





# Web survey design settings 【设置】

## Avoid breakoffs

1. incentives
2. length (the sample - decide - reconsider model)
   - 20-minute survey 20% breakoff rate compared to a 10-min one
3. section-transition
   - try not to use too many section transition
   - avoid complicated questions on the first page (otherwise respondents will anticipate burden)
     - no matrix question on first page
     - no multiple and open-ended questions on first page
   - **never use a slider bar**



## Distribute web survey

1. primary ways: URL, QR code, PDF

   - use shortened URL

2. pay attention to the screen resolution and security settings requirement when designing web survey

   - 1% - 5% people have script-disabled, as a result the interative content cannot be displayed
   - allow the survey to be displayed under the lowest screen resolution possible

3. consistency in display

   - take the survey to all devices/browser/screen/phone to test

4. mobile device

   >  disadvantages: take the whole screen, force people to scroll, less visibility; takes longer to download
   >
   > eg. a 10-min survey takes 2 min longer to load on smartphone compared to desktop

   - put on note discouraging participation via mobile device

   > eg. *... but take much longer if you are using a smartphone*
   >
   > very few respondents do the survey on smartphone when told not to do so (works)
   >
   > some respondents do the survey on computer when told not to do so 

5. email invitation

   - subject line

     - don't put recepient's name in the subject line

     - avoid words that will be spam-filtered

       > eg. *Act now; Free; Get paid*

     - use university name

       > eg. *UAlbany University Survey; WSU student experience survey invitation*

   - specify where it comes from

     - include sender name
     - use professional and full name

   - personalize contacts

     >  takes longer but worth it, respondents feel more responsibility and less likely to take it as spam

   - content of the email: URL

   - use 4 - 5 contacts

     - all need to have a link

     - don't need a prenotice

     - change the subject line slightly to make contacts differ

       > eg. last contact: *Thank you (not Urge); Last chance to help WSU; final reminder*

   

## Basic design

1. font and background

   > two concerns:
   >
   > - readability & meaning: legible, easy to read in computer screen; color meaning, infer meaning, contrast issue
   > - contrast between font and background should be strong so that fonts jumps out

   - serif (like Times New Roman)vs san serif (like Arial): use san serif
     - Arial: font preference
     - Tahoma: read fast
   - use black font on light color (white) background, use light blue if needs coloring
   - patterned background not recommended because it distracts people and slow them down

2. header, footer, &  respondent region

   - title in the header
   - contact information in the footer
   - questionnaire stays in the middle, within the respondent region, don't deviate from it
   - header, footer, and respondent region should be consistent across the questionnaire

3. page layout & alignment

   > Real-world eye-tracker shows:
   >
   > - upper left proportion is where their eyes start, stay longest, and linger longest
   > - bottom right is the least visible part
   > - banner blindness: respondents don't look at the banner again / ignore the banner once start

   - Left line your question; align on top left
   - don't put information in the banner

4. paging (click next for different pages) vs scrolling (one page, scroll down): use paging

   > advantages of paging: 
   >
   > - send every page
   > - navigation
   > - give you more control over delivery (like skip order)
   > - most of the time more than 1 question in a page
   >
   > problemss of scrolling:
   >
   > - data is not sent until finish
   >
   > - increase item nonresponse because people may accidentally scroll past a question
   >
   > - longer completion time
   >
   > - respondents may change their answer accidentally
   >
   >   eg. drop box: if you scroll down without clicking outside, your answer changes
   >
   > - if the questionnaire is long, the slide bar will be smaller, it's harder to get to the position accurately
   > - harder to do on smartphone

5. requiring answer or not

   - sometimes necessary for screening questions
   - other than that, shouldn't do it

   > Concerns:
   >
   > - if the respondents don't want to answer, they drop or lie
   > - inconsistent with voluntary survey requirement, IRB doesn't like it

6. progress indicator (like 25% complete): don't use it 

   > Concerns:
   >
   > - it is encouraging based on the assumption that each question takes the same time, but it is often not the case
   > - if open-ended question on the first page and there is progress indicator, respondents feel the indicator lies to them and will be pissed off
   > - if it moves fast at the beginning but slowly at the end (hard question at the end): less likely to skip, item nonresponse rate decreases, breakoff rate decreases
   > - if it moves slowly at the beginning but fast at the end: discouraging

   - can do it in an intermittent way: indicator only pop up in transition
   - can make it always on demand: don't help at all, but won't hurt
   - without using a progress indicator, the first part of the questionnaire is the key; if the respondents complete the first part faster, they like the survey better, then they stick to it, answer hard questions, and it benefits the whole questionnaire

7. error messages: use them and tailor them to specific questions

   - tell the respondents what they did wrong
   - don't just tell them the answer does not match what we need

8. questionnaire length

   - follow the 15-min cutoff
   - 8-10 min average
   - have lay persons take the survey, time them to test the length

   > Concerns: longer questionnaire, higher breakoff rate; self report engagement decreases as length increases



## Question setting

1. selective emphasis and instructions
   - don't use italics to emphasize, italics is harder to read than non-italics
   - don't use underline and color to emphasize, respondents will assume it is a link
   - use capitalization to emphasize (helpful, but distracting if used too much)
   - use same font and size for question stem and response options, but balded the stem, keep the response options not balded 
   - use italics for instructions (indicating optional, don't have to read)
   - don't place definition & instructions in navigational path because people will miss it
   - put the instructions between the stems/before the question stem

2. definitions & explanations in case that respondents don't know what the words mean

   - scroll/click to pop up vs automatically pop up vs base on age vs build into question stem: put in actual question

     > advantages: visibility & easy so that people use it more; respondents can be deterred by little bit of effort
     
   - don't place definition & instructions in navigational path because people will miss it



## Response format & scales

1. strong convention about response format, need to follow it

   - radio button for single choice questions

   - check box for multiple answer questions (check all that apply)

   - Drop boxes for nonvisible answers (like states)

   - never use scroll boxes with some options visible 

     > Concerns: visibility has priming effects; every format produces some priming effects; scroll boxes have the biggest priming effect

2. alignment of response options: vertical vs horizontal vs mixed: use vertical

   - multiple columns artificially increase the response of first option in the second column / the second category in the first row
   - vertical alignment minimizes sideway scroll when displaying on a smartphone

3. visual analog scale vs discrete response scale: use discrete response scale

   > Concerns about visual analog scale:
   >
   > - high breakoff rate when using visual analog scale, increases item missing
   > - require script/flash to display, people may have it blocked
   > - people not familiar with it, therefore don't like it, especially for the older and less educated group

4. running tallies (like sum up to 100): use it to improve the quality of answers

   > still have concerns like arbitrarily adjusting to get 100, but did a better job

5. grid/matrix questions

   - shade out the rows completed to avoid accidentally skipping 
   - shade by the row, not by cell

   > Caution:
   >
   > - matrix questions are automatically transformed to single questions on smartphones
   > - should consider the effect of different formats; see mobile device instructions in [Distribute web survey](# Distribute web survey)

6. open-ended questions

   - should avoid because it is harder to type

   - size of text box affects responses, see open-ended question in [Ensure consistent response](# Ensure consistent response)

   - provide more information if question stems are easily confusing

     > eg. county vs country: when asking for the name of the county, it is better to specify within US to avoid mistaking it for country, like asking the respondents to provide US county name

7. number effect of scale points

   - don't use negative numbers 

     > eg. scale from 1 - 5 is different from scale from -2 - 2, respondents tend to go to 2 most positive categories

   - don't use color 

8. picture: don't use unless you have to 

   > Concerns:
   >
   > - pictures have 2 types of effects
   >   - assimilation effect: answer more similar to the picture / go to the direction of the picture
   >   - contrast effect: go different/opposite to the picture 
   >   - eg. compared to a hospital lady, health evaluation increases
   > - recall information that can be inferred from pictures
   > - narrow interpretations

## Response heuristics

[Tourangeau et al., 2013](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3954164/)

- middle means typical/central
- left & top means first
- near means related 
- like (in apprearance) means close (in meaning)
- up means good (upper/higher on screen: ranked favorably)
- some labels outweight the others (verbal > numerical > color)





